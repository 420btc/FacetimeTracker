<div align="center">
  <img src="/public/iconox.png" alt="FaceTime Tracker Logo" width="200" />
  <h1>FaceTime Tracker</h1>
  <p>Monitor de Tiempo de ExposiciÃ³n a la CÃ¡mara</p>
  <p><em>Creado por Carlos Freire - 23 de Mayo 2025</em></p>
  
  [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
  [![GitHub stars](https://img.shields.io/github/stars/420btc/facedetection?style=social)](https://github.com/420btc/facedetection/stargazers)
  [![GitHub issues](https://img.shields.io/github/issues/420btc/facedetection)](https://github.com/420btc/facedetection/issues)
</div>

## ğŸ¯ Â¿QuÃ© es FaceTime Tracker?

FaceTime Tracker es una aplicaciÃ³n web que utiliza inteligencia artificial para detectar y registrar el tiempo que pasas frente a la cÃ¡mara. Especialmente Ãºtil para medir la exposiciÃ³n a videollamadas, clases virtuales o cualquier actividad que requiera el uso de cÃ¡mara web. Con una interfaz intuitiva, te permite llevar un registro detallado de tu tiempo de exposiciÃ³n a la cÃ¡mara, con estadÃ­sticas y visualizaciones fÃ¡ciles de entender.

## âœ¨ CaracterÃ­sticas Principales

- ğŸ‘ï¸ **DetecciÃ³n facial en tiempo real** con TensorFlow.js
- â±ï¸ **Registro preciso** del tiempo de exposiciÃ³n con historial detallado
- ğŸ“Š **Panel de estadÃ­sticas** con grÃ¡ficos interactivos
- ğŸ”” **Notificaciones** para recordatorios de descanso
- ğŸŒ“ **Modo oscuro/claro** para mayor comodidad visual
- ğŸ“± **DiseÃ±o responsivo** que funciona en cualquier dispositivo
- ğŸ”„ **SincronizaciÃ³n** entre dispositivos (prÃ³ximamente)
- ğŸ”’ **Privacidad primero**: Todo el procesamiento ocurre localmente

## ğŸš€ Empezando

### Requisitos Previos

- Node.js 16.14 o superior
- NPM 8.0 o superior
- Navegador web moderno (Chrome, Firefox, Edge, Safari)
- CÃ¡mara web

### InstalaciÃ³n

1. Clona el repositorio:
   ```bash
   git clone https://github.com/420btc/facedetection.git
   cd facedetection
   ```

2. Instala las dependencias:
   ```bash
   npm install
   # o
   yarn install
   ```

3. Inicia el servidor de desarrollo:
   ```bash
   npm run dev
   # o
   yarn dev
   ```

4. Abre tu navegador y visita:
   ```
   http://localhost:3000
   ```

## ğŸ› ï¸ TecnologÃ­as Utilizadas

### Frontend
- **Next.js 13+** - Framework de React para aplicaciones web
- **TypeScript** - JavaScript tipado para mejor desarrollo
- **Tailwind CSS** - Utilidades CSS para un diseÃ±o rÃ¡pido
- **Chart.js** - Para visualizaciÃ³n de datos
- **Framer Motion** - Animaciones fluidas

### IA y Procesamiento
- **TensorFlow.js** - Para detecciÃ³n facial en el navegador
- **Face Landmarks Detection** - Modelo de detecciÃ³n de puntos faciales

### Otras Herramientas
- **ESLint** - AnÃ¡lisis de cÃ³digo estÃ¡tico
- **Prettier** - Formateo de cÃ³digo
- **Husky** - Git hooks

## ğŸ“ Uso

1. **Iniciar una nueva sesiÃ³n**: Haz clic en "Iniciar Monitoreo"
2. **Permite el acceso a la cÃ¡mara** cuando tu navegador lo solicite
3. **Mantente en el marco de la cÃ¡mara** para el seguimiento
4. **Revisa tus estadÃ­sticas** en tiempo real
5. **Consulta tu historial** de sesiones anteriores

## âš™ï¸ ConfiguraciÃ³n

Puedes personalizar la aplicaciÃ³n modificando el archivo `.env.local`:

```env
NEXT_PUBLIC_APP_NAME=FaceTime Tracker
NEXT_PUBLIC_DEFAULT_SESSION_MINUTES=60
NEXT_PUBLIC_REMINDER_MINUTES=20
```

## ğŸ¤ ContribuciÃ³n

Â¡Las contribuciones son bienvenidas! Por favor, lee nuestras [pautas de contribuciÃ³n](CONTRIBUTING.md) para mÃ¡s detalles.

1. Haz un Fork del proyecto
2. Crea una rama para tu caracterÃ­stica (`git checkout -b feature/AmazingFeature`)
3. Haz commit de tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Haz push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Consulta el archivo [LICENSE](LICENSE) para mÃ¡s informaciÃ³n.

## ğŸ™ Reconocimientos

- Equipo de TensorFlow.js por su increÃ­ble biblioteca
- Comunidad de cÃ³digo abierto por su apoyo continuo
- A todos los contribuyentes que ayudan a mejorar este proyecto

## ğŸ“ Contacto

Carlos Freire - [@tu_usuario](https://twitter.com/tu_usuario) - correo@ejemplo.com

Enlace del proyecto: [https://github.com/420btc/facedetection](https://github.com/420btc/facedetection)

---

<div align="center">
  Hecho con â¤ï¸ por la comunidad de cÃ³digo abierto
</div>

### ğŸ“¦ Otros MÃ³dulos Clave
- `@tensorflow/tfjs`: Biblioteca principal de TensorFlow.js
- `@tensorflow-models/face-landmarks-detection`: Modelo pre-entrenado para detecciÃ³n de puntos faciales
- `react-webcam`: Componente de React para acceder a la cÃ¡mara web
- `tailwindcss`: Framework CSS para estilos rÃ¡pidos y responsivos

## ğŸš€ CÃ³mo Empezar

### Requisitos Previos
- Node.js 16.8 o superior
- NPM o Yarn
- Navegador web moderno con soporte para WebGL

### InstalaciÃ³n

1. Clona el repositorio:
   ```bash
   git clone [URL_DEL_REPOSITORIO]
   cd mi-app-deteccion-facial
   ```

2. Instala las dependencias:
   ```bash
   npm install
   # o
   yarn install
   ```

3. Inicia el servidor de desarrollo:
   ```bash
   npm run dev
   # o
   yarn dev
   ```

4. Abre [http://localhost:3000](http://localhost:3000) en tu navegador.

## ğŸ“ Uso

1. Concede los permisos de cÃ¡mara cuando se te solicite.
2. La aplicaciÃ³n comenzarÃ¡ a detectar automÃ¡ticamente tu rostro.
3. El contador registrarÃ¡ el tiempo que pasas frente a la cÃ¡mara.
4. Revisa tu historial de sesiones en la secciÃ³n correspondiente.

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. SiÃ©ntete libre de abrir un issue o enviar un pull request.

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo `LICENSE` para mÃ¡s detalles.

---

<p align="center">
  <em>Desarrollado con â¤ï¸ por Carlos Freire</em>
</p>

